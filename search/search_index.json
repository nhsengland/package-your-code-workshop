{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Package Your Code Workshop","text":"<p>Welcome to the Package Your Code workshop! This workshop is designed to teach NHS data scientists and analysts how to package their code effectively for better collaboration, distribution, and reuse. In this workshop, you'll master the essential skills for creating professional, reusable Python packages. You'll learn how to manage dependencies, package your code using modern standards, and create comprehensive documentation.</p> <p>Pre-requisite Knowledge</p> <p>The workshop assumes that participants have a basic understanding of the following concepts:</p> Pre-requisite Description Python Knowledge of how to write and run Python code Git Basic command line usage and version control concepts GitHub Familiarity with repositories, Codespaces, and forking RAP Understanding of the core principles of Reproducible Analytical Pipelines (RAP), particularly the levels of RAP Virtual Environments &amp; Package Management Basic understanding of virtual environments and package management in Python (e.g., <code>pip</code> and <code>venv</code>)"},{"location":"#core-workshop-topics","title":"Core Workshop Topics","text":"<ul> <li> <p>Dependency Management</p> <ul> <li>Using <code>uv</code> for fast, reliable dependency management</li> <li>Organizing dependencies into production, development, and documentation categories</li> <li>Creating and managing virtual environments</li> </ul> </li> <li> <p>Packaging with pyproject.toml</p> <ul> <li>Understanding the modern Python packaging standard</li> <li>Configuring project metadata and dependencies</li> <li>Making your code installable and reusable</li> </ul> </li> <li> <p>Documentation with MkDocs</p> <ul> <li>Setting up professional documentation with MkDocs Material</li> <li>Using mkdocstrings for automatic API documentation</li> <li>Creating user-friendly guides and tutorials</li> </ul> </li> </ul>"},{"location":"#bonus-content","title":"Bonus Content","text":"<p>Explore these additional topics at your own pace:</p> <ul> <li>Cookiecutter Templates - Quickly scaffold new projects</li> <li>Pre-Commit Hooks - Automate code quality checks</li> <li>CI/CD with GitHub Actions - Automate testing and deployment</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to begin? Check out our Getting Started guide to set up your development environment and begin the workshop.</p>"},{"location":"getting_started/","title":"Getting Started","text":"<p>This guide will help you set up your development environment to participate in the Package Your Code workshop. Follow the steps below to ensure you can dive into the workshop content smoothly.</p>"},{"location":"getting_started/#fork-the-repository","title":"Fork the Repository","text":"<ol> <li>Navigate to the Package Your Code Workshop GitHub repository</li> <li>Click the \"Fork\" button in the top-right corner to create a copy of the repository under your GitHub account.</li> <li>Click \"Create fork\" to confirm.</li> </ol>"},{"location":"getting_started/#open-in-github-codespaces","title":"Open in GitHub Codespaces","text":"<ol> <li>In your forked repository, click the green \"Code\" button.</li> <li>Select the \"Codespaces\" tab.</li> <li>Click \"Create codespace on main\" to launch a new Codespace instance. This may take a few moments to set up.</li> <li>Once the Codespace is ready, you will be taken to a VS Code environment in your browser. The repository will be cloned, and the development environment will be configured automatically, give it a few moments to finish setting up.</li> </ol>"},{"location":"getting_started/#fire-up-the-mkdocs-server","title":"Fire Up the MkDocs Server","text":"<ol> <li>Open a new terminal in the Codespace (Terminal &gt; New Terminal).</li> <li>Run the following command to start the MkDocs development server: <code>mkdocs serve</code></li> <li>Once the server is running, you will see a message indicating that the site is being served at a URL. Click on the URL to open the documentation in a new browser tab. This will update automatically as you make changes to the documentation files (which will happen in the MKDocs section of the workshop).</li> </ol> <p>Stop the server</p> <p>To stop the MkDocs server, return to the terminal where it's running and press <code>Ctrl + C</code>.</p>"},{"location":"getting_started/#find-your-first-workshop","title":"Find your first workshop","text":"<p>Head over to the workshops section of the website to get started with the workshop content.</p>"},{"location":"api_reference/","title":"API Reference","text":"<p>This section will contain the automatically generated API documentation for the NHS Hospital Analysis package.</p> <p>This section will be completed during the MkDocs workshop where you'll learn to set up automatic API documentation.</p>"},{"location":"workshops/","title":"Workshop Overview","text":"<p>Lets dive into these workshops! Each workshop will take</p> <p>Learning Objectives</p> <p>By the end of these workshops, you'll be able to:</p> <ul> <li>Manage Python dependencies professionally</li> <li>Package your code for easy distribution and reuse</li> <li>Create comprehensive documentation that your users will love</li> <li>Set up automated quality checks and deployment pipelines</li> <li>Apply RAP principles to your data science projects</li> </ul>"},{"location":"workshops/#workshop-path","title":"Workshop Path","text":""},{"location":"workshops/#core-workshops-live-session","title":"Core Workshops (Live Session)","text":"<p>Complete these workshops in order during the live session:</p>"},{"location":"workshops/#dependency-management","title":"Dependency Management","text":"<ul> <li>Master modern Python package management with <code>uv</code></li> <li>Organize dependencies by purpose (production, development, docs)</li> <li>Create reproducible environments</li> </ul>"},{"location":"workshops/#packaging-with-pyprojecttoml","title":"Packaging with pyproject.toml","text":"<ul> <li>Configure project metadata and dependencies</li> <li>Make your code installable and reusable</li> <li>Follow modern Python packaging standards</li> </ul>"},{"location":"workshops/#documentation-with-mkdocs","title":"Documentation with MkDocs","text":"<ul> <li>Create professional documentation websites</li> <li>Automatically generate API documentation</li> <li>Deploy documentation to GitHub Pages</li> </ul>"},{"location":"workshops/#bonus-workshops-self-paced","title":"Bonus Workshops (Self-Paced)","text":"<p>Explore these advanced topics at your own pace:</p>"},{"location":"workshops/#cookiecutter-templates","title":"Cookiecutter Templates","text":"<ul> <li>Create reusable project templates</li> <li>Standardise team workflows</li> <li>Rapid project scaffolding</li> </ul>"},{"location":"workshops/#pre-commit-hooks","title":"Pre-Commit Hooks","text":"<ul> <li>Automate code quality checks</li> <li>Prevent common mistakes</li> <li>Enforce coding standards</li> </ul>"},{"location":"workshops/#cicd-with-github-actions","title":"CI/CD with GitHub Actions","text":"<ul> <li>Automate testing and deployment</li> <li>Build and publish packages</li> <li>Continuous integration best practices</li> </ul> <p>Getting Help</p> <p>During the workshops:</p> <ul> <li>Ask questions - Don't hesitate to ask for clarification</li> <li>Discussion time - Share your experiences and learn from others</li> <li>Stuck on something? - The facilitators are here to help</li> </ul> <p>Outside of the workshops, don't hesitate to open an issue in the repository if you encounter any problems or have suggestions for improvement.</p>"},{"location":"workshops/cookiecutter_templates/","title":"Cookiecutter Templates","text":"<p>Bonus Workshop - Self-Paced</p> <p>Learn how to create reusable project templates with Cookiecutter.</p> <p>Coming soon...</p>"},{"location":"workshops/dependency_management/","title":"Dependency Management: From pip to UV","text":"<p>Learn how to modernize your Python dependency management by building on traditional <code>pip + venv</code> workflows and transitioning to modern tools like <code>uv</code> for better organization and performance.</p> <p>Learning Objectives</p> <ul> <li>Master pip + venv fundamentals that form the foundation of Python dependency management</li> <li>Organize dependencies using <code>pyproject.toml</code> for better structure and maintainability</li> <li>Understand how simple requirements become complex dependency trees</li> <li>Introduce UV as a modern Python package manager built on solid foundations</li> <li>Create reproducible environments using lockfiles and dependency groups</li> </ul> Why This Matters for RAP <p>This workshop directly supports Silver RAP by teaching you to include comprehensive dependency information in your repository. You'll learn to structure dependencies using <code>pyproject.toml</code>, which not only ensures reproducibility but also shapes your analytical pipeline into a proper package - a key step toward Gold RAP's \"code is fully packaged\" requirement.</p>"},{"location":"workshops/dependency_management/#task-1-understanding-traditional-python-dependency-management","title":"Task 1: Understanding Traditional Python Dependency Management","text":"<p>Let's start by setting up a traditional Python environment to understand the current approach and its limitations.</p>"},{"location":"workshops/dependency_management/#11-create-a-virtual-environment","title":"1.1 Create a Virtual Environment","text":"<p>First, let's create a clean virtual environment using the standard <code>venv</code> module:</p> <p>Virtual Environment Basics</p> <p>Virtual environments isolate your project dependencies from your system Python installation. The <code>.venv</code> directory contains a complete Python installation specific to your project.</p> <pre><code># Create a new virtual environment\npython -m venv .venv\n\n# Activate the virtual environment\nsource .venv/bin/activate\n\n# Verify we're in the virtual environment\nwhich python\n</code></pre>"},{"location":"workshops/dependency_management/#12-examine-current-dependencies","title":"1.2 Examine Current Dependencies","text":"<p>Let's look at what dependencies our project needs:</p> <pre><code># View the current requirements file\ncat requirements.txt\n</code></pre> <p>You should see a mix of dependencies including documentation tools, development tools, and core project dependencies.</p>"},{"location":"workshops/dependency_management/#13-install-dependencies-and-observe-complexity","title":"1.3 Install Dependencies and Observe Complexity","text":"<p>Now let's install these dependencies and see what actually gets installed:</p> <pre><code># Install all requirements\npip install -r requirements.txt\n\n# See what was actually installed (this will be much longer!)\npip freeze\n</code></pre> <p>Dependency Explosion</p> <p>Notice how our simple requirements file with ~10 packages resulted in many more installed packages. These are sub-dependencies (dependencies of dependencies) that pip resolved automatically.</p>"},{"location":"workshops/dependency_management/#understanding-traditional-approach-limitations","title":"Understanding Traditional Approach Limitations","text":"<p>The traditional <code>pip + venv</code> approach works well for basic projects but has some challenges as projects grow:</p> <ul> <li>Mixed dependency purposes: Production, development, and documentation dependencies are all in one file</li> <li>Sub-dependency visibility: <code>pip freeze</code> shows all packages, making it hard to distinguish your direct dependencies</li> <li>Slower resolution: pip can be slow with complex dependency trees</li> <li>No built-in lockfiles: Reproducible environments require manual <code>pip freeze</code> management</li> </ul> <p><code>pip</code> and <code>venv</code> is still valid</p> <p>Don't worry - <code>pip</code> and <code>venv</code> is still a perfectly valid approach for many projects! We're building on this solid foundation, not replacing it entirely.</p>"},{"location":"workshops/dependency_management/#task-2-organizing-dependencies-with-pyprojecttoml","title":"Task 2: Organizing Dependencies with pyproject.toml","text":"<p>Before we introduce <code>uv</code>, let's improve our dependency organization using the modern <code>pyproject.toml</code> standard.</p>"},{"location":"workshops/dependency_management/#21-understanding-pyprojecttoml-structure","title":"2.1 Understanding pyproject.toml Structure","text":"<p>Complete pyproject.toml Guide</p> <p>This section focuses on dependency management within pyproject.toml. For comprehensive coverage of project metadata, dynamic versioning, and tool configuration, see our Packaging with pyproject.toml workshop.</p> <p>The <code>pyproject.toml</code> file is the modern standard for Python project configuration. For detailed guidance on writing pyproject.toml files, see the official writing guide. Let's examine our current minimal setup:</p> <pre><code># View current pyproject.toml\ncat pyproject.toml\n</code></pre>"},{"location":"workshops/dependency_management/#22-add-project-dependencies","title":"2.2 Add Project Dependencies","text":"<p>Let's organize our dependencies by purpose. Open <code>pyproject.toml</code> and add the following sections:</p> <pre><code>[project] # (1)!\nname = \"package-your-code-workshop\"\nversion = \"0.1.0\"\ndescription = \"A workshop demonstrating Python packaging best practices\"\ndependencies = [ # (2)!\n    \"pandas&gt;=2.1.0\",\n    \"numpy&gt;=1.25.0\",\n    \"matplotlib&gt;=3.7.0\",\n    \"seaborn&gt;=0.12.0\",\n    \"plotly&gt;=5.15.0\",\n    \"oops_its_a_pipeline@git+https://github.com/nhsengland/oops-its-a-pipeline.git\", # (3)!\n    \"nhs_herbot@git+https://github.com/nhsengland/nhs_herbot.git\",\n]\n\n[dependency-groups] # (4)!\ndocs = [ # (5)!\n    \"mkdocs&gt;=1.5.0\",\n    \"mkdocs-material&gt;=9.0.0\",\n    \"mkdocstrings&gt;=0.22.0\",\n    \"mkdocstrings-python&gt;=1.0.0\",\n]\ndev = [ # (6)!\n    \"ruff&gt;=0.4.0\",\n    \"pytest&gt;=7.4.0\",\n]\n\n[tool.setuptools.packages.find] # (7)!\ninclude = [\"practice_level_gp_appointments*\"]\n</code></pre> <ol> <li>Core project metadata section following PEP 621</li> <li>Core dependencies required for your application to run in production</li> <li>Git-based dependencies - packages installed directly from repositories</li> <li>Dependency groups for development tools following PEP 735</li> <li>Documentation generation dependencies - only needed when building docs</li> <li>Development tools - only needed when coding and testing</li> <li>Build tool configuration - tells setuptools which packages to include</li> </ol> <p>Why Separate Groups?</p> <p>Now you can install exactly what you need:</p> <pre><code># Traditional approach - everything mixed together\npip install -r requirements.txt  # ~50 packages\n\n# Modern approach - install selectively\npip install -e .         # Core dependencies only\npip install -e .[dev]    # Core + development tools\npip install -e .[docs]   # Core + documentation tools\n</code></pre> Dependency Groups: Modern Best Practice <p>We're using <code>dependency-groups</code> as the modern best practice for development tools:</p> <pre><code># Modern approach - dependency groups for dev tools\n[dependency-groups]\ndev = [\"pytest\", \"ruff\"]\ndocs = [\"mkdocs\", \"mkdocs-material\"]\n</code></pre> <p>Dependency groups are specifically designed for development tools, testing, and build processes. They're supported by modern tools like UV and newer versions of pip.</p> <p>For backwards compatibility with older pip versions, you can still use: <pre><code># Fallback approach - optional dependencies\n[project.optional-dependencies]\ndev = [\"pytest\", \"ruff\"]\ndocs = [\"mkdocs\", \"mkdocs-material\"]  \n</code></pre></p>"},{"location":"workshops/dependency_management/#23-test-the-new-structure","title":"2.3 Test the New Structure","text":"<p>Let's clean our environment and test our new dependency structure:</p> <pre><code># Deactivate and remove the old environment\ndeactivate\nrm -rf .venv\n\n# Create a fresh environment\npython -m venv .venv\nsource .venv/bin/activate\n\n# Install just core dependencies\npip install -e .\n\n# Test that our package is accessible\npython -c \"import practice_level_gp_appointments; print('Success!')\"\n\n# Now install development tools too\npip install -e .[dev]\n\n# Install everything\npip install -e .[dev,docs]\n</code></pre>"},{"location":"workshops/dependency_management/#task-3-introducing-uv","title":"Task 3: Introducing UV","text":"<p>Now let's introduce UV, a modern Python package manager built in Rust that builds on the foundations we've established.</p>"},{"location":"workshops/dependency_management/#31-install-uv","title":"3.1 Install UV","text":"<p>Let's install UV on your system:</p> <pre><code># Install UV (macOS/Linux)\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n# Restart your shell or source the new PATH\nsource ~/.bashrc  # or ~/.zshrc depending on your shell # (1)!\n\n# Verify installation\nuv --version\n</code></pre> <ol> <li>To check the type of shell you're using, run <code>echo $SHELL</code>. If it ends with <code>zsh</code>, use <code>source ~/.zshrc</code> instead.</li> </ol> <p>Windows Installation</p> <p>On Windows, use: <code>powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"</code>. For more installation options, see the UV installation guide.</p>"},{"location":"workshops/dependency_management/#32-migrate-existing-project-to-uv","title":"3.2 Migrate Existing Project to UV","text":"<p>Let's migrate our existing project to use UV while keeping our pyproject.toml structure. For a comprehensive migration guide, see Migrating from pip to a UV project:</p> <pre><code># First, clean the current environment\ndeactivate\nrm -rf .venv\n\n# Create a UV-managed virtual environment\nuv venv\n\n# Activate the environment\nsource .venv/bin/activate\n\n# Install dependencies from pyproject.toml\nuv sync --all-groups\n</code></pre> <p>UV Sync Command</p> <p><code>uv sync</code> reads your <code>pyproject.toml</code> and installs all dependencies. The <code>--all-groups</code> flag includes all dependency groups (dev, docs, etc.).</p>"},{"location":"workshops/dependency_management/#33-practice-selective-installation-with-uv","title":"3.3 Practice: Selective Installation with UV","text":"<p>Now let's practice using UV's dependency groups with the same <code>optional-dependencies</code> syntax.</p>"},{"location":"workshops/dependency_management/#practice-different-installation-patterns","title":"Practice Different Installation Patterns","text":"<p>Let's practice installing dependencies for different use cases using our existing pyproject.toml structure:</p> <pre><code># Start with a clean slate\ndeactivate\nrm -rf .venv\n\n# 1. Core dependencies only (production-like)\nuv venv\nsource .venv/bin/activate\nuv sync\npip list  # See what got installed\n\n# 2. Add development tools\nuv sync --group dev\npip list  # Notice the additional packages\n\n# 3. Clean and try docs only\ndeactivate\nrm -rf .venv\nuv venv\nsource .venv/bin/activate\nuv sync --group docs\npip list  # Just core + docs packages\n\n# 4. Everything for full development\nuv sync --all-groups\npip list  # All packages\n</code></pre> Real-World Scenarios <p>New Developer Setup: A developer working on code (not docs) <pre><code>uv sync --group dev\n</code></pre></p> <p>Documentation Writer: Someone updating docs (not coding) <pre><code>uv sync --group docs\n</code></pre></p> <p>Production Deployment: Server needs only core functionality <pre><code>uv sync  # No groups = core only\n</code></pre></p> <p>CI/CD Pipeline: Different jobs, different needs <pre><code># Testing job\n- run: uv sync --group dev\n\n# Documentation job  \n- run: uv sync --group docs\n\n# Production deployment\n- run: uv sync\n</code></pre></p>"},{"location":"workshops/dependency_management/#34-alternative-building-a-project-from-scratch-with-uv","title":"3.4 Alternative: Building a Project from Scratch with UV","text":"<p>Let's also practice the \"greenfield\" approach - starting a completely new project with UV:</p> <pre><code># Clean everything\ndeactivate\nrm -rf .venv uv.lock\n\n# Initialize a new UV project\nuv init --name package-your-code-workshop --python 3.12\n\n# Create and activate environment\nuv venv --python 3.12\nsource .venv/bin/activate\n\n# Add dependencies one by one (UV builds pyproject.toml automatically)\nuv add pandas numpy matplotlib seaborn plotly\n\n# Add development dependencies\nuv add --group dev ruff pytest\n\n# Add documentation dependencies  \nuv add --group docs mkdocs mkdocs-material mkdocstrings mkdocstrings-python\n\n# Check what UV created\ncat pyproject.toml\n</code></pre> UV Auto-Generation <p>UV automatically creates and updates your <code>pyproject.toml</code> as you add dependencies. This is great for new projects where you want to build up dependencies incrementally.</p>"},{"location":"workshops/dependency_management/#35-understanding-uv-lockfiles","title":"3.5 Understanding UV Lockfiles","text":"<p>UV automatically creates a <code>uv.lock</code> file for reproducible builds. Let's explore it:</p> <pre><code># Check if lockfile exists\nls -la uv.lock\n\n# Look at the lockfile structure\nhead -20 uv.lock\n\n# Install from exact lockfile versions\nuv sync --frozen\n</code></pre> <p>Always Commit Lockfiles</p> <p>Add <code>uv.lock</code> to version control to ensure everyone gets exactly the same dependency versions. This is essential for RAP Gold standard reproducibility - your analytical pipelines will run identically across different environments and team members.</p>"},{"location":"workshops/dependency_management/#task-4-working-with-uv-in-practice","title":"Task 4: Working with UV in Practice","text":"<p>Let's explore common UV workflows you'll use in daily development. For comprehensive guidance on UV project workflows, see the Working on Projects guide.</p>"},{"location":"workshops/dependency_management/#41-adding-and-removing-dependencies","title":"4.1 Adding and Removing Dependencies","text":"<pre><code># Add a new dependency\nuv add requests\n\n# Add a development dependency\nuv add --group dev mypy\n\n# Remove a dependency\nuv remove requests\n\n# Upgrade all dependencies\nuv lock --upgrade\n</code></pre>"},{"location":"workshops/dependency_management/#42-managing-environments","title":"4.2 Managing Environments","text":"<pre><code># Create environment with specific Python version\nuv venv --python 3.11\n\n# List available Python versions\nuv python list\n\n# Install a specific Python version (if needed)\nuv python install 3.11\n</code></pre>"},{"location":"workshops/dependency_management/#43-running-commands","title":"4.3 Running Commands","text":"<pre><code># Run commands in the UV environment\nuv run python --version\n\n# Run the package as a module (uses __main__.py)\nuv run python -m practice_level_gp_appointments\n\n# Run a specific script file\nuv run python practice_level_gp_appointments/pipeline.py\n\n# Run tools from your environment\nuv run ruff check .\n</code></pre> <p>UV Run</p> <p><code>uv run</code> automatically activates the virtual environment and runs the command, even if you haven't manually activated the environment.</p>"},{"location":"workshops/dependency_management/#migration-command-reference","title":"Migration Command Reference","text":"<p>Here's a quick reference for migrating from pip workflows to UV:</p> Traditional pip Modern UV Purpose <code>pip install package</code> <code>uv add package</code> Add new dependency <code>pip install -r requirements.txt</code> <code>uv sync</code> Install all dependencies <code>pip install -e .</code> <code>uv sync</code> Install project in development mode <code>pip freeze &gt; requirements.txt</code> <code>uv export &gt; requirements.txt</code> Export current environment <code>pip install --upgrade package</code> <code>uv add package --upgrade</code> Upgrade package <code>python script.py</code> <code>uv run python script.py</code> Run Python script Command Details <p>Key differences to note:</p> <ul> <li><code>uv sync</code> installs your project and dependencies from <code>pyproject.toml</code></li> <li><code>uv export</code> creates requirements.txt from the current environment</li> <li><code>uv lock</code> updates the lockfile (separate from installation)</li> <li>All UV commands automatically handle virtual environments</li> </ul>"},{"location":"workshops/dependency_management/#best-practices","title":"Best Practices","text":""},{"location":"workshops/dependency_management/#dependency-group-organization","title":"Dependency Group Organization","text":"<p>Keep It Simple: Two Groups</p> <p>For most projects, you only need two dependency groups:</p> <ul> <li>Core dependencies (<code>dependencies</code>): What your app needs to run</li> <li>Development dependencies (<code>dev</code>): Tools for coding, testing, linting</li> </ul> <p>Simple, effective setup: <pre><code>[project]\ndependencies = [\"pandas\", \"requests\"]\n\n[dependency-groups]\ndev = [\"pytest\", \"ruff\"]\n</code></pre></p> <p>Installation: <pre><code># With UV (modern)\nuv sync --group dev\n\n# With pip (fallback - use optional-dependencies)\npip install -e .[dev]\n</code></pre></p> Advanced: More Granular Groups <p>If your project grows complex, you can break down further:</p> <ul> <li><code>docs</code>: Documentation generation tools</li> <li><code>test</code>: Testing-specific dependencies (separate from general dev)</li> <li><code>typing</code>: Type checking tools (mypy, type stubs)</li> <li><code>jupyter</code>: Jupyter notebook dependencies</li> </ul> <p>Example comprehensive setup: <pre><code>[dependency-groups]\ndev = [\"ruff\", \"pytest\"]\ntest = [\"pytest\", \"pytest-cov\"]\ndocs = [\"mkdocs\", \"mkdocs-material\"]\ntyping = [\"mypy\", \"types-requests\"]\n</code></pre></p> <p>But honestly, most projects don't need this complexity!</p>"},{"location":"workshops/dependency_management/#installation-patterns","title":"Installation Patterns","text":"<p>Two Commands You'll Use Most</p> <pre><code># Production deployment\nuv sync\n\n# Development work  \nuv sync --group dev\n</code></pre> <p>That's it! Simple and effective.</p> Other Installation Options <pre><code># Install everything (if you have multiple groups)\nuv sync --all-groups\n\n# Install specific groups only\nuv sync --group docs\nuv sync --group test\n\n# Multiple specific groups\nuv sync --group dev --group test\n</code></pre>"},{"location":"workshops/dependency_management/#working-on-locked-down-platforms","title":"Working on Locked-Down Platforms","text":"<p>When You Can't Install UV</p> <p>Many enterprise/NHS environments don't allow installing new tools like UV. The good news? The organized dependency structure still helps with traditional pip!</p> <p>With organized pyproject.toml, you can still benefit: <pre><code># Use pip with optional dependencies\npip install -e .              # Core dependencies only\npip install -e .[dev]         # Core + development tools\n\n# Or export to requirements files for teams\nuv export --group dev &gt; requirements-dev.txt  # (when UV is available)\n# Then share requirements-dev.txt for pip users\npip install -r requirements-dev.txt\n</code></pre></p> <p>Key benefits even with just pip: - Clear separation of production vs development dependencies - Easy to share specific requirement sets with team members - Future-ready when you can eventually use modern tools like Poetry or Hatch - Better project organization and documentation</p>"},{"location":"workshops/dependency_management/#do-this","title":"Do This","text":"<ul> <li>Organize dependencies: Use <code>pyproject.toml</code> to separate production and development dependencies</li> <li>Use the tools available: UV when possible, pip when necessary - both work with organized dependencies</li> <li>Pin appropriately: Use <code>&gt;=</code> for minimum versions, avoid overly specific pins</li> <li>Document your setup: Make it clear how team members should install dependencies</li> <li>Plan for constraints: Consider locked-down environments when choosing your approach</li> </ul>"},{"location":"workshops/dependency_management/#avoid-this","title":"Avoid This","text":"<ul> <li>All dependencies in one place: Don't mix production and development dependencies</li> <li>Unpinned dependencies: Specify minimum versions for stability</li> <li>Over-pinning: Avoid exact version pins unless absolutely necessary</li> <li>Assuming everyone can use modern tools: Not everyone can install UV on their systems</li> </ul>"},{"location":"workshops/dependency_management/#troubleshooting","title":"Troubleshooting","text":""},{"location":"workshops/dependency_management/#common-issues","title":"Common Issues","text":"<p>Package Not Found</p> <pre><code># Clear cache and retry\nuv cache clean\nuv sync --all-groups\n</code></pre> <p>Version Conflicts</p> <pre><code># Use UV's conflict resolution options\nuv add package-name --resolution lowest-direct\n</code></pre> <p>Environment Issues</p> <pre><code># Start completely fresh\nrm -rf .venv uv.lock\nuv venv\nuv sync --all-groups\n</code></pre>"},{"location":"workshops/dependency_management/#checkpoint","title":"Checkpoint","text":"<p>Before moving to the next workshop, verify you can:</p> <ul> <li> Create and activate virtual environments with both <code>venv</code> and <code>uv</code></li> <li> Understand the difference between direct and sub-dependencies</li> <li> Organize dependencies in <code>pyproject.toml</code> using dependency groups</li> <li> Install dependencies with both <code>pip</code> and <code>uv sync</code></li> <li> Add and remove packages using UV commands</li> <li> Understand the purpose of <code>uv.lock</code> files</li> </ul>"},{"location":"workshops/dependency_management/#next-steps","title":"Next Steps","text":"<p>Excellent work! You've successfully modernized your dependency management workflow while building on solid <code>pip + venv</code> foundations.</p> <p>Continue your learning journey - these workshops can be done in any order:</p> <ul> <li>Packaging with pyproject.toml - Make your code installable and reusable</li> <li>Documentation with MkDocs - Create professional documentation</li> <li>Pre-Commit Hooks - Automate code quality checks</li> <li>CI/CD with GitHub Actions - Automate testing and deployment</li> </ul> Additional Resources"},{"location":"workshops/dependency_management/#rap-community-of-practice","title":"RAP Community of Practice","text":"<ul> <li>Why Use Virtual Environments - RAP guidance on virtual environments for reproducible analysis</li> </ul>"},{"location":"workshops/dependency_management/#uv-modern-python-package-manager","title":"UV (Modern Python Package Manager)","text":"<ul> <li>UV Documentation - Complete UV guide and reference</li> <li>UV Working on Projects - Practical UV project workflows</li> <li>UV Migration Guide - Step-by-step pip to UV migration</li> <li>UV vs pip Comparison - Detailed comparison of tools</li> </ul>"},{"location":"workshops/dependency_management/#python-project-configuration","title":"Python Project Configuration","text":"<ul> <li>Writing pyproject.toml - Official guide to pyproject.toml</li> <li>PEP 621 - Project Metadata - Standard for pyproject.toml</li> <li>PEP 735 - Dependency Groups - Modern dependency organization</li> </ul>"},{"location":"workshops/dependency_management/#traditional-python-packaging","title":"Traditional Python Packaging","text":"<ul> <li>Python Packaging Guide - Official Python packaging documentation</li> <li>Virtual Environments Guide - Python.org official guide</li> <li>pip User Guide - Official pip documentation</li> </ul>"},{"location":"workshops/dependency_management/#best-practices-standards","title":"Best Practices &amp; Standards","text":"<ul> <li>Python Packaging Best Practices - Official packaging guidelines</li> <li>Understanding Semantic Versioning - Version specification standards</li> <li>Python Enhancement Proposals (PEPs) - Python standards and proposals</li> </ul>"},{"location":"workshops/github_actions/","title":"CI/CD with GitHub Actions","text":"<p>Bonus Workshop - Self-Paced</p> <p>Learn how to automate testing, building, and deployment with GitHub Actions.</p> <p>Coming soon...</p>"},{"location":"workshops/mkdocs_documentation/","title":"Documentation with MkDocs: From Setup to GitHub Pages","text":"<p>Learn how to create professional documentation for your Python projects using MkDocs Material, generate automatic API documentation, and deploy to GitHub Pages.</p> <p>Learning Objectives</p> <ul> <li>Set up MkDocs with Material theme and NHS styling</li> <li>Understand mkdocs.yml configuration structure</li> <li>Generate automatic API documentation with mkdocstrings</li> <li>Create and organize documentation pages</li> <li>Deploy your documentation to GitHub Pages</li> </ul> <p>Why This Matters for RAP</p> <p>Professional documentation is essential for Silver RAP, which requires \"well-documented code including user guidance, explanation of code structure &amp; methodology.\" This workshop teaches you to create documentation that meets these standards automatically.</p>"},{"location":"workshops/mkdocs_documentation/#task-1-understanding-mkdocs-and-material-theme-setup","title":"Task 1: Understanding MkDocs and Material Theme Setup","text":"<p>Let's explore how MkDocs is already configured in this repository with NHS Data Science team styling.</p>"},{"location":"workshops/mkdocs_documentation/#11-examine-the-current-setup","title":"1.1 Examine the Current Setup","text":"<p>First, let's look at the mkdocs.yml configuration file:</p> <pre><code># View the MkDocs configuration\ncat mkdocs.yml\n</code></pre> <p>MkDocs Basics</p> <p>MkDocs is a fast, simple static site generator for building project documentation. Material for MkDocs is a popular theme that provides a modern, responsive design.</p>"},{"location":"workshops/mkdocs_documentation/#12-key-configuration-sections","title":"1.2 Key Configuration Sections","text":"<p>Let's understand the main parts of our mkdocs.yml:</p>"},{"location":"workshops/mkdocs_documentation/#site-information","title":"Site Information","text":"<pre><code>site_name: Package Your Code Workshop # (1)!\nsite_description: NHS Data Science Workshop - Package Your Code # (2)!\nsite_author: Joseph Wilson - NHS England - Data Science and Applied AI Team # (3)!\nsite_url: https://nhsengland.github.io/package-your-code-workshop # (4)!\n</code></pre> <ol> <li>Display name shown in browser tab and site header - keep it concise and descriptive</li> <li>Brief description for search engines and social media sharing - appears in meta tags</li> <li>Author information for attribution and contact - helps with project ownership clarity</li> <li>Full URL where the site will be deployed - enables proper linking and canonical URLs</li> </ol>"},{"location":"workshops/mkdocs_documentation/#material-theme-configuration","title":"Material Theme Configuration","text":"<pre><code>theme:\n  name: material # (1)!\n  language: en # (2)!\n  custom_dir: docs/overrides # (3)!\n  palette:\n    scheme: default # (4)!\n    primary: indigo # (5)!\n  logo: images/logo/nhs-blue-on-white.jpg # (6)!\n  favicon: images/favicon/favicon.ico # (7)!\n</code></pre> <ol> <li>Use the Material theme for MkDocs - provides modern, responsive design</li> <li>Set the site language to English for proper accessibility and SEO</li> <li>Point to custom NHS templates and styling overrides</li> <li>Use the default (light) colour scheme - can also be 'slate' for dark mode</li> <li>Set primary colour to indigo to match NHS branding guidelines</li> <li>NHS logo displayed in the site header navigation</li> <li>Custom favicon for the browser tab - uses NHS branding</li> </ol>"},{"location":"workshops/mkdocs_documentation/#navigation-structure","title":"Navigation Structure","text":"<pre><code>nav:\n  - Home: index.md # (1)!\n  - Getting Started: getting_started.md # (2)!\n  - Workshops: # (3)!\n    - workshops/index.md # (4)!\n    - Dependency Management: workshops/dependency_management.md # (5)!\n    # ... more workshops\n  - API Reference: # (6)!\n    - api_reference/index.md # (7)!\n</code></pre> <ol> <li>Main landing page - provides project overview and quick start information</li> <li>Detailed setup guide for getting the project running locally</li> <li>Workshop section with dropdown navigation for all tutorials</li> <li>Workshop index page explaining the learning path and prerequisites</li> <li>Individual workshop pages - each covers a specific packaging topic</li> <li>API Reference section for automatically generated documentation</li> <li>API index page with overview of all modules and quick examples</li> </ol> <p>NHS Styling</p> <p>This repository uses NHS branding with custom colours, logos, and styling. The <code>custom_dir: docs/overrides</code> points to NHS-specific templates and the <code>extra_css</code> section includes NHS styling.</p>"},{"location":"workshops/mkdocs_documentation/#13-test-the-current-setup","title":"1.3 Test the Current Setup","text":"<p>Let's run the documentation server to see what we have:</p> With UV (If you've done Dependency Management)With pip + venv (Basic Setup) <p>If you've completed the Dependency Management workshop:</p> <pre><code># Activate your UV environment\nsource .venv/bin/activate\n\n# Install documentation dependencies with UV\nuv sync --group docs\n\n# Start the development server\nmkdocs serve\n</code></pre> <p>Using the basic repository setup with requirements.txt:</p> <pre><code># Create and activate virtual environment (if not already done)\npython -m venv .venv\nsource .venv/bin/activate\n\n# Install documentation dependencies from requirements.txt\npip install -r requirements.txt\n\n# Start the development server\nmkdocs serve\n</code></pre> <p>Visit <code>http://127.0.0.1:8000</code> to see the documentation site running locally.</p> <p>Using GitHub Codespaces?</p> <p>If you're running this in GitHub Codespaces, the port will be automatically forwarded. Look for a popup notification or check the Ports tab at the bottom of your VS Code interface. The forwarded URL will look like <code>https://your-codespace-name-8000.preview.app.github.dev/</code></p> <p>Port Already in Use?</p> <p>If port 8000 is busy, MkDocs will automatically try 8001, 8002, etc. Check the terminal output for the actual URL.</p>"},{"location":"workshops/mkdocs_documentation/#task-2-creating-api-documentation-with-mkdocstrings","title":"Task 2: Creating API Documentation with mkdocstrings","text":"<p>Now let's generate automatic API documentation for our Python package using mkdocstrings.</p>"},{"location":"workshops/mkdocs_documentation/#21-understand-mkdocstrings-configuration","title":"2.1 Understand mkdocstrings Configuration","text":"<p>Our mkdocs.yml already includes mkdocstrings setup:</p> <pre><code>plugins:\n  - mkdocstrings: # (1)!\n      handlers:\n        python: # (2)!\n          options:\n            docstring_style: numpy # (3)!\n            members_order: source # (4)!\n            show_source: true # (5)!\n            show_bases: true # (6)!\n</code></pre> <ol> <li>The mkdocstrings plugin automatically generates API documentation from your Python docstrings</li> <li>Use the Python handler to process Python modules and extract documentation</li> <li>Parse docstrings using NumPy format - supports Parameters, Returns, Examples sections</li> <li>Display class members and functions in the same order they appear in source code</li> <li>Include links to the actual source code on GitHub for each function/class</li> <li>Show base classes for inheritance relationships in class documentation</li> </ol> Docstring Styles <p>mkdocstrings supports multiple docstring formats:</p> <p>NumPy - Structured sections with clear parameter descriptions <pre><code>def add(x, y):\n    \"\"\"Add two numbers.\n\n    Parameters\n    ----------\n    x : int\n        First number\n    y : int\n        Second number\n\n    Returns\n    -------\n    int\n        Sum of x and y\n    \"\"\"\n</code></pre></p> <p>Google - Clean, readable format popular in modern Python <pre><code>def add(x, y):\n    \"\"\"Add two numbers.\n\n    Args:\n        x (int): First number\n        y (int): Second number\n\n    Returns:\n        int: Sum of x and y\n    \"\"\"\n</code></pre></p> <p>Sphinx - Traditional reStructuredText format <pre><code>def add(x, y):\n    \"\"\"Add two numbers.\n\n    :param x: First number\n    :type x: int\n    :param y: Second number\n    :type y: int\n    :return: Sum of x and y\n    :rtype: int\n    \"\"\"\n</code></pre></p> <p>PEP 257 - Basic Python docstring conventions <pre><code>def add(x, y):\n    \"\"\"Add two numbers and return the result.\"\"\"\n</code></pre></p> <p>mkdocstrings can automatically detect and parse mixed styles within the same project, making it flexible for teams with varying documentation preferences.</p>"},{"location":"workshops/mkdocs_documentation/#22-examine-existing-python-modules","title":"2.2 Examine Existing Python Modules","text":"<p>Let's look at the structure of our Python package:</p> <pre><code># List the Python modules in our package\nls -la practice_level_gp_appointments/\n\n# Look at an example module with docstrings\nhead -20 practice_level_gp_appointments/data_processing.py\n</code></pre>"},{"location":"workshops/mkdocs_documentation/#23-create-api-documentation-pages","title":"2.3 Create API Documentation Pages","text":"<p>Now let's create documentation pages for each module. First, examine the current API reference structure:</p> <pre><code># Check what's in the API reference directory\nls -la docs/content/api_reference/\ncat docs/content/api_reference/index.md\n</code></pre> <p>Let's create individual documentation pages for each module. We'll start with the data processing module:</p> <ol> <li>Create a new file called <code>data_processing.md</code> in the <code>docs/content/api_reference/</code> directory</li> <li>Add the following content:</li> </ol> <pre><code># Data Processing Module\n\n::: practice_level_gp_appointments.data_processing\n</code></pre> <p>mkdocstrings Syntax</p> <p>The <code>module.name</code> syntax tells mkdocstrings to automatically generate documentation for that module, including all functions, classes, and their docstrings.</p> Create the Other Module Pages <p>Now create the remaining API documentation pages following the same pattern:</p> <p>Create <code>analytics.md</code> in <code>docs/content/api_reference/</code>: <pre><code># Analytics Module\n\n::: practice_level_gp_appointments.analytics\n</code></pre></p> <p>Create <code>visualization.md</code> in <code>docs/content/api_reference/</code>: <pre><code># Visualization Module\n\n::: practice_level_gp_appointments.visualization\n</code></pre></p> <p>Create <code>output.md</code> in <code>docs/content/api_reference/</code>: <pre><code># Output Module\n\n::: practice_level_gp_appointments.output\n</code></pre></p> <p>Create <code>pipeline.md</code> in <code>docs/content/api_reference/</code>: <pre><code># Pipeline Module\n\n::: practice_level_gp_appointments.pipeline\n</code></pre></p>"},{"location":"workshops/mkdocs_documentation/#24-update-navigation","title":"2.4 Update Navigation","text":"<p>Now let's add these new pages to our navigation in mkdocs.yml:</p> <pre><code>nav:\n  # ... existing navigation ...\n  - API Reference: # (1)!\n    - api_reference/index.md # (2)!\n    - Data Processing: api_reference/data_processing.md # (3)!\n    - Analytics: api_reference/analytics.md # (4)!\n    - Visualization: api_reference/visualization.md # (5)!\n</code></pre> <ol> <li>Top-level navigation item with dropdown menu for API documentation</li> <li>Overview page explaining the API structure and providing quick examples</li> <li>Dedicated page for data processing functions (loading, cleaning, transforming)</li> <li>Dedicated page for analytical functions (statistics, summaries, calculations)</li> <li>Dedicated page for visualization functions (charts, plots, dashboards)</li> </ol> <p>Edit mkdocs.yml Carefully</p> <p>YAML is sensitive to indentation. Make sure to maintain the same indentation level as existing items in the nav section.</p>"},{"location":"workshops/mkdocs_documentation/#25-test-api-documentation","title":"2.5 Test API Documentation","text":"<p>Let's see our API documentation in action:</p> <pre><code># If mkdocs serve is still running, it should auto-reload\n# Otherwise, restart it:\nmkdocs serve\n</code></pre> <p>Navigate to the API Reference section and explore the automatically generated documentation.</p> <p>What You Should See</p> <ul> <li>Function signatures with parameter types</li> <li>Docstring content formatted nicely</li> <li>Source code links</li> <li>Class inheritance information</li> </ul>"},{"location":"workshops/mkdocs_documentation/#task-3-customizing-and-organizing-documentation","title":"Task 3: Customizing and Organizing Documentation","text":"<p>Let's improve our documentation structure and add some custom content.</p>"},{"location":"workshops/mkdocs_documentation/#31-create-a-comprehensive-api-reference-index","title":"3.1 Create a Comprehensive API Reference Index","text":"<p>Let's update the API reference index page to include package-level auto-documentation and a clean navigation table:</p> <ol> <li>Open the file <code>docs/content/api_reference/index.md</code></li> <li>Replace its contents with:</li> </ol> <pre><code># API Reference\n\n::: practice_level_gp_appointments\n\n## Module Documentation\n\n| Module | Description | Key Components |\n|--------|-------------|----------------|\n| [Data Processing](data_processing.md) | Data loading, cleaning, and transformation | DataLoadingStage, DataJoiningStage |\n| [Analytics](analytics.md) | Statistical analysis and summaries | SummarisationStage |\n| [Visualization](visualization.md) | Chart generation and plotting | Visualization functions |\n| [Output](output.md) | Data export and report generation | OutputStage |\n| [Pipeline](pipeline.md) | Pipeline orchestration and workflow | NHSPracticeAnalysisPipeline |\n</code></pre> <p>Complete Documentation</p> <p>The <code>practice_level_gp_appointments</code> directive automatically generates comprehensive documentation from the package's docstrings, imports, and version information.</p>"},{"location":"workshops/mkdocs_documentation/#32-update-navigation","title":"3.2 Update Navigation","text":"<p>Now let's add all these new pages to our navigation in mkdocs.yml. You'll need to update the API Reference section:</p> <pre><code>nav:\n  # ... existing navigation ...\n  - API Reference: # (1)!\n    - api_reference/index.md # (2)!\n    - Data Processing: api_reference/data_processing.md # (3)!\n    - Analytics: api_reference/analytics.md # (4)!\n    - Visualization: api_reference/visualization.md # (5)!\n    - Output: api_reference/output.md # (6)!\n    - Pipeline: api_reference/pipeline.md # (7)!\n</code></pre> <ol> <li>Top-level navigation item with dropdown menu for API documentation</li> <li>Overview page with package documentation and navigation table</li> <li>Dedicated page for data processing functions and classes</li> <li>Dedicated page for analytical functions and classes</li> <li>Dedicated page for visualization functions and classes</li> <li>Dedicated page for output and export functions</li> <li>Dedicated page for pipeline orchestration classes</li> </ol> <p>Edit mkdocs.yml Carefully</p> <p>YAML is sensitive to indentation. Make sure to maintain the same indentation level as existing items in the nav section.</p>"},{"location":"workshops/mkdocs_documentation/#33-test-your-api-documentation","title":"3.3 Test Your API Documentation","text":"<p>Now let's see your API documentation in action:</p> <pre><code># If mkdocs serve is still running, it should auto-reload\n# Otherwise, restart it:\nmkdocs serve\n</code></pre> <p>Visit <code>http://127.0.0.1:8000</code> and navigate to the API Reference section.</p> <p>Using GitHub Codespaces?</p> <p>If you're running this in GitHub Codespaces, use the forwarded URL from the Ports tab instead of localhost. It will look like <code>https://your-codespace-name-8000.preview.app.github.dev/</code></p> <p>What You Should See</p> <p>On the API Reference index page: - Package description and version from the <code>__init__.py</code> file - All available classes and functions imported at package level - Clean navigation table with links to each module</p> <p>On individual module pages: - Function signatures with parameter types - Docstring content formatted nicely with sections - Source code links (if configured) - Class inheritance information</p> <p>Overall navigation: - API Reference dropdown in the main navigation - Each module accessible from the dropdown menu</p>"},{"location":"workshops/mkdocs_documentation/#task-4-deploying-to-github-pages","title":"Task 4: Deploying to GitHub Pages","text":"<p>Now let's set up your documentation to be deployed to GitHub Pages using the manual method. GitHub Pages is a free static site hosting service can serve your documentation directly from your repository. In this workshop, we'll use the manual deployment method where you build locally and push to a <code>gh-pages</code> branch.</p> <p>Make sure you are on a forked repository!</p> <p>If you're following this workshop as part of the complete package-your-code workshop series, you're likely already working on your own fork. You can skip the forking step and continue with the repository you've been using.</p> <p>Find out how to fork the repository in the Getting Started guide.</p> Automatic Deployment with GitHub Actions <p>You can also set up automatic deployment using GitHub Actions, which builds and deploys your documentation automatically when you push changes. This is covered in detail in the CI/CD with GitHub Actions workshop.</p> <p>The automated approach uses workflows that run on GitHub's servers, eliminating the need to build locally and ensuring documentation stays up-to-date with every code change.</p>"},{"location":"workshops/mkdocs_documentation/#41-enable-github-pages","title":"4.1 Enable GitHub Pages","text":"<ol> <li>Go to your repository on GitHub</li> <li>Click Settings tab</li> <li>Scroll down to Pages section</li> <li>Under Source, select Deploy from a branch</li> <li>Choose gh-pages branch and / (root) folder</li> <li>Click Save</li> </ol> <p>No gh-pages Branch Yet?</p> <p>Don't worry! We'll create it in the next step. GitHub Pages will show an error until we deploy for the first time.</p>"},{"location":"workshops/mkdocs_documentation/#42-deploy-using-mkdocs","title":"4.2 Deploy Using MkDocs","text":"<p>MkDocs has a built-in deployment command for GitHub Pages:</p> With UV (If you've done Dependency Management)With pip + venv (Basic Setup) <p>If you've completed the Dependency Management workshop:</p> <pre><code># Build and deploy to GitHub Pages with UV\nuv run mkdocs gh-deploy\n\n# This command:\n# 1. Runs mkdocs through UV's environment\n# 2. Builds your documentation\n# 3. Creates/updates the gh-pages branch\n# 4. Pushes to GitHub\n</code></pre> <p>Using the basic repository setup with requirements.txt:</p> <pre><code># Build and deploy to GitHub Pages\nmkdocs gh-deploy\n\n# This command:\n# 1. Builds your documentation\n# 2. Creates/updates the gh-pages branch\n# 3. Pushes to GitHub\n</code></pre> <p>First Deployment</p> <p>After the first <code>mkdocs gh-deploy</code>, your site will be available at: <code>https://YOUR-USERNAME.github.io/package-your-code-workshop/</code></p>"},{"location":"workshops/mkdocs_documentation/#45-test-your-deployment","title":"4.5 Test Your Deployment","text":"<p>After deployment:</p> <ol> <li>Visit your GitHub Pages URL</li> <li>Test all navigation links</li> <li>Verify API documentation displays correctly</li> <li>Check that images and styling work</li> </ol> <p>Updates</p> <p>To update your documentation, simply run <code>mkdocs gh-deploy</code> again after making changes to your documentation files.</p>"},{"location":"workshops/mkdocs_documentation/#checkpoint","title":"Checkpoint","text":"<p>Before moving to the next workshop, verify you can:</p> <ul> <li> Understand mkdocs.yml configuration structure</li> <li> Run <code>mkdocs serve</code> to preview documentation locally</li> <li> Create API documentation pages using mkdocstrings</li> <li> Add new pages to the navigation structure</li> <li> Deploy documentation to GitHub Pages using <code>mkdocs gh-deploy</code></li> <li> Access your documentation at your GitHub Pages URL</li> </ul>"},{"location":"workshops/mkdocs_documentation/#next-steps","title":"Next Steps","text":"<p>Excellent work! You've created professional documentation that meets RAP standards.</p> <p>Continue your learning journey - these workshops can be done in any order:</p> <ul> <li>Dependency Management - Modern Python dependency management</li> <li>Packaging with pyproject.toml - Make your code installable and reusable</li> <li>Pre-Commit Hooks - Automate code quality checks</li> <li>CI/CD with GitHub Actions - Automate testing and deployment</li> </ul> Additional Resources"},{"location":"workshops/mkdocs_documentation/#mkdocs-and-material-theme","title":"MkDocs and Material Theme","text":"<ul> <li>MkDocs Documentation - Official MkDocs guide</li> <li>Material for MkDocs - Complete Material theme documentation</li> <li>MkDocs Configuration - mkdocs.yml reference</li> <li>Material Theme Setup - Getting started with Material</li> </ul>"},{"location":"workshops/mkdocs_documentation/#api-documentation","title":"API Documentation","text":"<ul> <li>mkdocstrings Documentation - Automatic API documentation</li> <li>mkdocstrings Python Handler - Python-specific configuration</li> <li>NumPy Docstring Guide - Docstring formatting standards</li> <li>Google Style Docstrings - Alternative docstring format</li> </ul>"},{"location":"workshops/mkdocs_documentation/#github-pages-and-deployment","title":"GitHub Pages and Deployment","text":"<ul> <li>GitHub Pages Documentation - Official GitHub Pages guide</li> <li>MkDocs Deployment - Deployment options and strategies</li> <li>GitHub Actions for MkDocs - Automated deployment options</li> </ul>"},{"location":"workshops/mkdocs_documentation/#rap-documentation-standards","title":"RAP Documentation Standards","text":"<ul> <li>RAP Documentation Requirements - Silver RAP documentation standards</li> <li>NHS Digital Documentation Style - NHS content and style guidelines</li> </ul>"},{"location":"workshops/packaging_pyproject/","title":"Packaging with pyproject.toml: Modern Python Project Configuration","text":"<p>Learn how to properly configure your Python projects using pyproject.toml, the modern standard for Python packaging and project metadata.</p> <p>Learning Objectives</p> <ul> <li>Understand the current minimal pyproject.toml configuration</li> <li>Add comprehensive project metadata and information</li> <li>Configure dynamic version management from <code>__init__.py</code></li> <li>Set up tool configurations for code quality tools</li> <li>Follow modern Python packaging standards</li> </ul> <p>Why This Matters for RAP</p> <p>Proper project configuration is essential for Gold RAP and useful for Silver RAP. The pyproject.toml file standardizes how Python projects are configured, making them more maintainable, discoverable, and professional. For Silver RAP and above, many development tools and settings can be centrally configured in pyproject.toml.</p>"},{"location":"workshops/packaging_pyproject/#task-1-understanding-the-current-pyprojecttoml","title":"Task 1: Understanding the Current pyproject.toml","text":"<p>Let's examine what we currently have in our pyproject.toml file.</p> <p>You should see:</p> <pre><code>[project] # (1)!\nname = \"package-your-code-workshop\" # (2)!\nversion = \"0.1.0\" # (3)!\n\n[tool.setuptools.packages.find] # (4)!\ninclude = [\"practice_level_gp_appointments*\"] # (5)!\n</code></pre> <ol> <li>The <code>[project]</code> section contains core project metadata defined by PEP 621</li> <li>Project name - must be unique if publishing to PyPI, should follow Python naming conventions</li> <li>Static version number - we'll configure this to be dynamic later in the workshop</li> <li>Tool-specific configuration section for setuptools (our build backend)</li> <li>Tells setuptools which packages to include when building - the <code>*</code> includes subpackages</li> </ol>"},{"location":"workshops/packaging_pyproject/#task-2-adding-comprehensive-project-metadata","title":"Task 2: Adding Comprehensive Project Metadata","text":"<p>Let's expand our project configuration with proper metadata that makes our package professional and discoverable.</p>"},{"location":"workshops/packaging_pyproject/#21-add-core-project-information","title":"2.1 Add Core Project Information","text":"<p>Open your <code>pyproject.toml</code> file and replace the <code>[project]</code> section with your own details:</p> <p>Personalizing Your Package</p> <p>Make it yours! Replace \"Your Name\" and \"your.email@nhs.net\" with your actual details. This is important for:</p> <ul> <li>Attribution - You get credit for your work alongside the original author</li> <li>Contact - People know who to reach for questions about your contributions</li> <li>Professional development - Your name appears in package metadata</li> <li>Portfolio building - Contributes to your coding portfolio</li> </ul> <pre><code>[project]\nname = \"package-your-code-workshop\"\nversion = \"0.1.0\"\ndescription = \"NHS Data Science Workshop - Learn to package your Python code professionally\" # (1)!\nreadme = \"README.md\" # (2)!\nlicense = {text = \"MIT\"} # (3)!\nrequires-python = \"&gt;=3.9\" # (4)!\nauthors = [ # (5)!\n    {name = \"Joseph Wilson\", email = \"joseph.wilson@nhs.net\"}, # (6)!\n    {name = \"Your Name\", email = \"your.email@nhs.net\"}, # (7)!\n    {name = \"NHS England Data Science Team\"},\n]\nmaintainers = [ # (8)!\n    {name = \"NHS England Data Science Team\", email = \"datascience@nhs.net\"},\n]\nkeywords = [\"nhs\", \"data-science\", \"packaging\", \"workshop\", \"gp-appointments\"] # (9)!\n</code></pre> <ol> <li>Clear, concise description of what the project does</li> <li>Points to the README file for detailed project information</li> <li>License specification - references the MIT license in our LICENSE file</li> <li>Minimum Python version required - important for compatibility</li> <li>Authors who created the project - can include name and/or email</li> <li>The very good looking, talented, and, most of all, humble creator of this workshop</li> <li>Add your own name and email here - you're contributing to this project!</li> <li>Current maintainers responsible for ongoing development</li> <li>Keywords help with discoverability in package indexes</li> </ol>"},{"location":"workshops/packaging_pyproject/#22-add-project-urls-and-classifiers","title":"2.2 Add Project URLs and Classifiers","text":"<p>Continue adding to your <code>[project]</code> section:</p> <p>Customize Your Project URLs</p> <p>If you've completed the MkDocs Documentation workshop and set up GitHub Pages, update these URLs to point to your own repository and documentation:</p> <ul> <li>Homepage &amp; Documentation: <code>https://yourusername.github.io/package-your-code-workshop</code></li> <li>Repository: <code>https://github.com/yourusername/package-your-code-workshop</code></li> <li>Bug Tracker: <code>https://github.com/yourusername/package-your-code-workshop/issues</code></li> </ul> <p>This makes your package truly yours and showcases your own documentation site!</p> <pre><code>[project.urls] # (1)!\nHomepage = \"https://nhsengland.github.io/package-your-code-workshop\"\nDocumentation = \"https://nhsengland.github.io/package-your-code-workshop\"\nRepository = \"https://github.com/nhsengland/package-your-code-workshop\"\n\"Bug Tracker\" = \"https://github.com/nhsengland/package-your-code-workshop/issues\"\n\nclassifiers = [ # (2)!\n    \"Development Status :: 3 - Alpha\",\n    \"Intended Audience :: Healthcare Industry\",\n    \"Intended Audience :: Developers\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n    \"Programming Language :: Python :: 3\",\n    \"Programming Language :: Python :: 3.9\",\n    \"Programming Language :: Python :: 3.10\",\n    \"Programming Language :: Python :: 3.11\",\n    \"Programming Language :: Python :: 3.12\",\n    \"Topic :: Scientific/Engineering\",\n    \"Topic :: Software Development :: Libraries :: Python Modules\",\n]\n</code></pre> <ol> <li>URLs section provides important project links for users and tools - customize these!</li> <li>Classifiers categorize your project in package indexes like PyPI</li> </ol> <p>PyPI Classifiers</p> <p>PyPI Classifiers are standardized tags that help categorize packages. They improve discoverability and help users understand your project's purpose and compatibility.</p>"},{"location":"workshops/packaging_pyproject/#23-test-your-configuration","title":"2.3 Test Your Configuration","text":"<p>Let's verify our configuration is valid:</p> With UV (If you've done Dependency Management)With pip + venv (Basic Setup) <pre><code># Use traditional build tool for dry-run testing\nuv run python -m pip install build\nuv run python -m build --wheel --no-isolation --dry-run\n</code></pre> <p>Why not <code>uv build</code>?</p> <p>UV's <code>uv build</code> command doesn't have a <code>--dry-run</code> option, so we use the traditional build tool to test our configuration without creating files.</p> <pre><code># Check if pyproject.toml is valid and test build\npython -m pip install build\npython -m build --wheel --no-isolation --dry-run\n</code></pre> <p>What You Should See</p> <ul> <li>No syntax errors in the TOML format</li> <li>Build process completes successfully</li> <li>All metadata is properly recognized</li> </ul>"},{"location":"workshops/packaging_pyproject/#task-3-dynamic-version-management","title":"Task 3: Dynamic Version Management","text":"<p>Instead of manually updating version numbers in multiple places, let's configure dynamic versioning from our <code>__init__.py</code> file.</p>"},{"location":"workshops/packaging_pyproject/#31-examine-current-version-setup","title":"3.1 Examine Current Version Setup","text":"<p>First, let's see how version is currently defined:</p> <pre><code># Check the version in __init__.py\ngrep -n \"__version__\" practice_level_gp_appointments/__init__.py\n</code></pre>"},{"location":"workshops/packaging_pyproject/#32-configure-dynamic-versioning","title":"3.2 Configure Dynamic Versioning","text":"<p>Update your <code>[project]</code> section to use dynamic versioning:</p> <pre><code>[project]\nname = \"package-your-code-workshop\"\ndynamic = [\"version\"] # (1)!\ndescription = \"NHS Data Science Workshop - Learn to package your Python code professionally\"\n# ... rest of your project configuration\n</code></pre> <ol> <li>Tells build tools that version should be determined dynamically</li> </ol> <p>Then add the setuptools configuration to read from <code>__init__.py</code>:</p> <pre><code>[tool.setuptools.dynamic] # (1)!\nversion = {attr = \"practice_level_gp_appointments.__version__\"} # (2)!\n</code></pre> <ol> <li>Setuptools-specific configuration for dynamic fields</li> <li>Points to the <code>__version__</code> variable in our package's <code>__init__.py</code></li> </ol>"},{"location":"workshops/packaging_pyproject/#33-test-dynamic-versioning","title":"3.3 Test Dynamic Versioning","text":"<p>Let's verify the dynamic versioning works:</p> With UV (If you've done Dependency Management)With pip + venv (Basic Setup) <pre><code># Test the build again to ensure version is read correctly\nuv run python -m build --wheel --no-isolation --dry-run\n</code></pre> <pre><code># Test the build again to ensure version is read correctly\npython -m build --wheel --no-isolation --dry-run\n</code></pre> <p>Version Management Benefits</p> <ul> <li>Single source of truth - version only defined in <code>__init__.py</code></li> <li>Automatic consistency - build tools read the same version</li> <li>Easier releases - update version in one place</li> </ul> Alternative Versioning Approaches <p>Other dynamic versioning options include:</p> <p>From Git tags using <code>setuptools-scm</code>: <pre><code># In pyproject.toml\n[project]\ndynamic = [\"version\"]\n\n[tool.setuptools_scm]\n# Version from git tags (e.g., v1.0.0)\n</code></pre> <pre><code># Quick setup\npip install setuptools-scm\ngit tag v0.1.0  # Create your first tag\n</code></pre></p> <p>From a VERSION file: <pre><code># In pyproject.toml\n[tool.setuptools.dynamic]\nversion = {file = \"VERSION\"}\n</code></pre> <pre><code># Quick setup\necho \"0.1.0\" &gt; VERSION\n</code></pre></p> <p>From environment variables: <pre><code># In pyproject.toml\n[tool.setuptools.dynamic]\nversion = {attr = \"your_package._version.__version__\"}\n</code></pre> <pre><code># In your_package/_version.py\nimport os\n__version__ = os.getenv(\"PACKAGE_VERSION\", \"0.1.0-dev\")\n</code></pre></p>"},{"location":"workshops/packaging_pyproject/#task-4-configuring-development-tools","title":"Task 4: Configuring Development Tools","text":"<p>Let's configure code quality tools in our pyproject.toml to maintain consistent coding standards.</p>"},{"location":"workshops/packaging_pyproject/#41-configure-ruff-linter-and-formatter","title":"4.1 Configure Ruff (Linter and Formatter)","text":"<p>Add Ruff configuration to your pyproject.toml:</p> <pre><code>[tool.ruff] # (1)!\nline-length = 88 # (2)!\ntarget-version = \"py39\" # (3)!\n\n[tool.ruff.lint] # (4)!\nselect = [ # (5)!\n    \"E\",  # pycodestyle errors\n    \"W\",  # pycodestyle warnings\n    \"F\",  # Pyflakes\n    \"I\",  # isort\n    \"B\",  # flake8-bugbear\n    \"C4\", # flake8-comprehensions\n    \"UP\", # pyupgrade\n]\nignore = [ # (6)!\n    \"E501\", # line too long (handled by formatter)\n]\n\n[tool.ruff.lint.isort] # (7)!\nknown-first-party = [\"practice_level_gp_appointments\"]\n</code></pre> <ol> <li>Main Ruff configuration section</li> <li>Maximum line length (matches Black default)</li> <li>Target Python version for rule selection</li> <li>Linting-specific configuration</li> <li>Enable specific rule categories for comprehensive checking</li> <li>Disable rules that conflict with the formatter</li> <li>Configure import sorting with our package as first-party</li> </ol> <p>Now remove the old configuration file to avoid conflicts:</p> <pre><code># Remove the old ruff.toml file\nrm ruff.toml\n</code></pre> <p>Configuration Migration</p> <p>After adding Ruff configuration to pyproject.toml, delete the old ruff.toml file to prevent configuration conflicts. Ruff reads configuration in a specific order, and having both files can lead to unexpected behavior.</p>"},{"location":"workshops/packaging_pyproject/#42-test-ruff-configuration","title":"4.2 Test Ruff Configuration","text":"<p>Our repository already has Ruff installed and configured. Let's test our new pyproject.toml configuration:</p> With UV (If you've done Dependency Management)With pip + venv (Basic Setup) <pre><code># Run linting with our new pyproject.toml config\nuv run ruff check practice_level_gp_appointments/\n\n# Run formatting (shows what would change)\nuv run ruff format --diff practice_level_gp_appointments/\n</code></pre> <pre><code># Run linting with our new pyproject.toml config\nruff check practice_level_gp_appointments/\n\n# Run formatting (shows what would change)\nruff format --diff practice_level_gp_appointments/\n</code></pre> <p>Centralizing Configuration</p> <p>By moving Ruff configuration to pyproject.toml, we're centralizing all our project settings in one place. Ruff will automatically read the configuration from pyproject.toml.</p> <p>Ruff Benefits</p> <p>Ruff is extremely fast and combines multiple tools: - Linter (replaces flake8, isort, pyupgrade, and more) - Formatter (replaces Black) - Single tool instead of managing multiple dependencies</p>"},{"location":"workshops/packaging_pyproject/#43-additional-tool-configurations","title":"4.3 Additional Tool Configurations","text":"Other Common Tool Configurations <p>You can configure other development tools in pyproject.toml:</p> <p>Pytest Configuration: <pre><code>[tool.pytest.ini_options]\ntestpaths = [\"tests\"]\npython_files = [\"test_*.py\", \"*_test.py\"]\npython_classes = [\"Test*\"]\npython_functions = [\"test_*\"]\naddopts = \"-v --tb=short --strict-markers\"\nmarkers = [\n    \"slow: marks tests as slow\",\n    \"integration: marks tests as integration tests\",\n]\n</code></pre></p> <p>Black Formatter Configuration: <pre><code>[tool.black]\nline-length = 88\ntarget-version = ['py39']\ninclude = '\\.pyi?$'\nexclude = '''\n/(\n    \\.git\n  | \\.mypy_cache\n  | \\.tox\n  | \\.venv\n  | _build\n  | buck-out\n  | build\n  | dist\n)/\n'''\n</code></pre></p> <p>Coverage Configuration: <pre><code>[tool.coverage.run]\nsource = [\"practice_level_gp_appointments\"]\nomit = [\"*/tests/*\", \"*/test_*\"]\n\n[tool.coverage.report]\nexclude_lines = [\n    \"pragma: no cover\",\n    \"def __repr__\",\n    \"raise AssertionError\",\n    \"raise NotImplementedError\",\n]\n</code></pre></p> <p>MyPy Type Checking: <pre><code>[tool.mypy]\npython_version = \"3.9\"\nwarn_return_any = true\nwarn_unused_configs = true\ndisallow_untyped_defs = true\n</code></pre></p>"},{"location":"workshops/packaging_pyproject/#44-run-all-quality-checks","title":"4.4 Run All Quality Checks","text":"<p>Let's test our complete setup:</p> With UV (If you've done Dependency Management)With pip + venv (Basic Setup) <pre><code># Run ruff linting\nuv run ruff check practice_level_gp_appointments/\n\n# Run ruff formatting\nuv run ruff format practice_level_gp_appointments/\n\n# Test the build process\nuv run python -m build --wheel --no-isolation --dry-run\n</code></pre> <pre><code># Run ruff linting\nruff check practice_level_gp_appointments/\n\n# Run ruff formatting\nruff format practice_level_gp_appointments/\n\n# Test the build process\npython -m build --wheel --no-isolation --dry-run\n</code></pre> <p>Quality Assurance Complete</p> <p>Your pyproject.toml now provides: - Professional metadata for package discovery - Dynamic versioning for easier maintenance - Tool configuration for consistent code quality</p>"},{"location":"workshops/packaging_pyproject/#checkpoint","title":"Checkpoint","text":"<p>Before moving to the next workshop, verify you can:</p> <ul> <li> Understand the structure and purpose of pyproject.toml</li> <li> Add comprehensive project metadata including authors, description, and classifiers</li> <li> Configure dynamic version management from <code>__init__.py</code></li> <li> Set up and run code quality tools like Ruff</li> <li> Build your package successfully with proper metadata</li> </ul>"},{"location":"workshops/packaging_pyproject/#next-steps","title":"Next Steps","text":"<p>Excellent work! You've configured a professional Python project that follows modern standards.</p> <p>Continue your learning journey - these workshops can be done in any order:</p> <ul> <li>Dependency Management - Modern Python dependency management with UV</li> <li>Documentation with MkDocs - Professional documentation and API reference</li> <li>Pre-Commit Hooks - Automate code quality checks</li> <li>CI/CD with GitHub Actions - Automate testing and deployment</li> </ul> Additional Resources"},{"location":"workshops/packaging_pyproject/#pyprojecttoml-and-packaging","title":"pyproject.toml and Packaging","text":"<ul> <li>PEP 518 - pyproject.toml - Original specification</li> <li>PEP 621 - Project Metadata - Project metadata in pyproject.toml</li> <li>Python Packaging User Guide - Comprehensive packaging documentation</li> <li>PyPI Classifiers - Complete list of package classifiers</li> </ul>"},{"location":"workshops/packaging_pyproject/#code-quality-tools","title":"Code Quality Tools","text":"<ul> <li>Ruff Documentation - Fast Python linter and formatter</li> <li>Black Documentation - Python code formatter</li> <li>pytest Documentation - Testing framework</li> <li>MyPy Documentation - Static type checker</li> </ul>"},{"location":"workshops/packaging_pyproject/#build-tools-and-standards","title":"Build Tools and Standards","text":"<ul> <li>build Documentation - Python package build frontend</li> <li>setuptools Documentation - Python package build backend</li> <li>Wheel Format - Built distribution format</li> <li>TOML Specification - Configuration file format</li> </ul>"},{"location":"workshops/packaging_pyproject/#nhs-and-rap-standards","title":"NHS and RAP Standards","text":"<ul> <li>RAP Community of Practice - NHS RAP standards and guidance</li> </ul>"},{"location":"workshops/precommit_hooks/","title":"Pre-Commit Hooks","text":"<p>Bonus Workshop - Self-Paced</p> <p>Learn how to automate code quality checks with pre-commit hooks.</p> <p>Coming soon...</p>"}]}